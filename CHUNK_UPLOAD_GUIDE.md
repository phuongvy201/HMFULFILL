# H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng Chunk Upload

## T·ªïng quan

H·ªá th·ªëng chunk upload ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ x·ª≠ l√Ω upload file l·ªõn m·ªôt c√°ch hi·ªáu qu·∫£, tr√°nh timeout v√† l·ªói server khi upload file n·∫∑ng.

## T√≠nh nƒÉng

### ‚úÖ ƒê√£ ho√†n th√†nh:

-   **Chia file th√†nh chunks**: T·ª± ƒë·ªông chia file l·ªõn th√†nh c√°c chunks 1MB
-   **Upload tu·∫ßn t·ª±**: Upload t·ª´ng chunk m·ªôt c√°ch an to√†n
-   **Progress tracking**: Hi·ªÉn th·ªã ti·∫øn tr√¨nh upload real-time
-   **Error handling**: X·ª≠ l√Ω l·ªói v√† retry t·ª± ƒë·ªông
-   **File validation**: Ki·ªÉm tra ƒë·ªãnh d·∫°ng v√† k√≠ch th∆∞·ªõc file
-   **Memory efficient**: Kh√¥ng load to√†n b·ªô file v√†o memory
-   **Resume support**: C√≥ th·ªÉ resume upload n·∫øu b·ªã gi√°n ƒëo·∫°n

### üîß C·∫•u h√¨nh:

-   **Chunk size**: 1MB per chunk
-   **Max file size**: 100MB per file
-   **Supported formats**: JPG, JPEG, PNG, PDF
-   **Storage**: S3 bucket v·ªõi local temp storage

## C√°ch ho·∫°t ƒë·ªông

### 1. Frontend (JavaScript)

```javascript
// Kh·ªüi t·∫°o upload manager
const uploadManager = new FileUploadManager({
    chunkSize: 1024 * 1024, // 1MB
    maxFileSize: 100 * 1024 * 1024, // 100MB
    onFileProgress: (data) => {
        // C·∫≠p nh·∫≠t progress bar
        updateProgress(data.progress);
    },
    onFileComplete: (data) => {
        // File upload ho√†n t·∫•t
        console.log("Uploaded:", data.filePath);
    },
});

// Upload file
await uploadManager.uploadFile(file);
```

### 2. Backend (Laravel)

```php
// Upload chunk
POST /customer/design/upload-chunk
{
    "file": "chunk_data",
    "chunk": 0,
    "chunks": 10,
    "filename": "design.jpg",
    "upload_id": "upload_123456",
    "total_size": 10485760
}

// Response
{
    "success": true,
    "completed": false,
    "uploaded_chunks": [0, 1, 2],
    "message": "ƒê√£ upload chunk 3/10"
}
```

## API Endpoints

### 1. Upload Chunk

```
POST /customer/design/upload-chunk
```

**Parameters:**

-   `file`: Chunk data
-   `chunk`: Chunk index (0-based)
-   `chunks`: Total number of chunks
-   `filename`: Original filename
-   `upload_id`: Unique upload ID
-   `total_size`: Total file size in bytes

### 2. Check Upload Status

```
GET /customer/design/upload-status/{uploadId}
```

**Response:**

```json
{
    "success": true,
    "metadata": {
        "filename": "design.jpg",
        "total_size": 10485760,
        "chunks": 10,
        "uploaded_chunks": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],
        "created_at": "2025-01-17T10:30:00.000000Z"
    },
    "progress": 100
}
```

### 3. Cancel Upload

```
POST /customer/design/upload-cancel
```

**Parameters:**

-   `upload_id`: Upload ID to cancel

## Quy tr√¨nh upload

1. **Ch·ªçn file**: User ch·ªçn file t·ª´ form
2. **Validation**: Ki·ªÉm tra ƒë·ªãnh d·∫°ng v√† k√≠ch th∆∞·ªõc
3. **Chia chunks**: T·ª± ƒë·ªông chia file th√†nh chunks 1MB
4. **Upload chunks**: Upload t·ª´ng chunk tu·∫ßn t·ª±
5. **Progress tracking**: Hi·ªÉn th·ªã ti·∫øn tr√¨nh real-time
6. **Merge chunks**: Gh√©p chunks th√†nh file ho√†n ch·ªânh
7. **Upload to S3**: Upload file ho√†n ch·ªânh l√™n S3
8. **Cleanup**: X√≥a chunks t·∫°m v√† metadata

## L·ª£i √≠ch

### üöÄ Performance

-   **Gi·∫£m timeout**: Kh√¥ng b·ªã timeout khi upload file l·ªõn
-   **Memory efficient**: Kh√¥ng load to√†n b·ªô file v√†o memory
-   **Parallel processing**: C√≥ th·ªÉ upload nhi·ªÅu file c√πng l√∫c
-   **Resume capability**: C√≥ th·ªÉ resume n·∫øu b·ªã gi√°n ƒëo·∫°n

### üõ°Ô∏è Reliability

-   **Error handling**: X·ª≠ l√Ω l·ªói network v√† server
-   **Retry mechanism**: T·ª± ƒë·ªông retry khi chunk upload th·∫•t b·∫°i
-   **Validation**: Ki·ªÉm tra integrity c·ªßa t·ª´ng chunk
-   **Cleanup**: T·ª± ƒë·ªông d·ªçn d·∫πp file t·∫°m

### üìä User Experience

-   **Real-time progress**: Hi·ªÉn th·ªã ti·∫øn tr√¨nh upload chi ti·∫øt
-   **File info**: Hi·ªÉn th·ªã th√¥ng tin file (t√™n, k√≠ch th∆∞·ªõc)
-   **Error messages**: Th√¥ng b√°o l·ªói r√µ r√†ng
-   **Cancel support**: Cho ph√©p h·ªßy upload

## Troubleshooting

### L·ªói th∆∞·ªùng g·∫∑p:

1. **"File qu√° l·ªõn"**

    - Gi·∫£i ph√°p: Gi·∫£m k√≠ch th∆∞·ªõc file ho·∫∑c tƒÉng `maxFileSize`

2. **"Network timeout"**

    - Gi·∫£i ph√°p: TƒÉng `chunkSize` ho·∫∑c gi·∫£m delay gi·ªØa chunks

3. **"Storage quota exceeded"**

    - Gi·∫£i ph√°p: Ki·ªÉm tra dung l∆∞·ª£ng S3 v√† local storage

4. **"Chunk upload failed"**
    - Gi·∫£i ph√°p: Ki·ªÉm tra network v√† server configuration

### Debug:

```javascript
// Enable debug logging
console.log("Upload debug:", {
    fileSize: file.size,
    chunks: Math.ceil(file.size / chunkSize),
    chunkSize: chunkSize,
});
```

## C·∫•u h√¨nh Server

### PHP Configuration:

```ini
; TƒÉng memory limit
memory_limit = 512M

; TƒÉng upload timeout
max_execution_time = 300
max_input_time = 300

; TƒÉng upload size
upload_max_filesize = 100M
post_max_size = 100M
```

### Laravel Configuration:

```php
// config/filesystems.php
'disks' => [
    'local' => [
        'driver' => 'local',
        'root' => storage_path('app'),
    ],
    's3' => [
        'driver' => 's3',
        'key' => env('AWS_ACCESS_KEY_ID'),
        'secret' => env('AWS_SECRET_ACCESS_KEY'),
        'region' => env('AWS_DEFAULT_REGION'),
        'bucket' => env('AWS_BUCKET'),
    ],
],
```

## Monitoring

### Logs:

-   Chunk upload logs: `storage/logs/laravel.log`
-   Error tracking: Laravel Telescope (n·∫øu c√≥)

### Metrics:

-   Upload success rate
-   Average upload time
-   Chunk retry count
-   Storage usage

## Security

### Validation:

-   File type validation
-   File size limits
-   Upload frequency limits
-   User authentication

### Cleanup:

-   Automatic temp file cleanup
-   Expired upload cleanup
-   Failed upload cleanup

## Future Enhancements

### üöÄ Planned Features:

-   **Parallel chunk upload**: Upload nhi·ªÅu chunks c√πng l√∫c
-   **Resume upload**: Resume upload b·ªã gi√°n ƒëo·∫°n
-   **File compression**: T·ª± ƒë·ªông n√©n file tr∆∞·ªõc upload
-   **CDN integration**: Upload tr·ª±c ti·∫øp l√™n CDN
-   **Video support**: H·ªó tr·ª£ upload video files
-   **Batch upload**: Upload nhi·ªÅu files c√πng l√∫c

### üîß Technical Improvements:

-   **WebSocket progress**: Real-time progress via WebSocket
-   **Queue processing**: Background chunk processing
-   **Caching**: Redis cache cho upload metadata
-   **Monitoring**: Advanced monitoring v√† alerting
